{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "List of some todos for the paper..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerated Basic Algorithm\n",
    "\n",
    "1. [x] Benchmark properly current version (`e8b51ef01e034f600a0e5b91174abe65a0ce5127`)\n",
    "    - `numba1` results\n",
    "2. [x] Adapt to recycle slots in the numpy jet arrays\n",
    "    1. Add a jet_index array, that maps a numpy slot to the Python PseudoJets structure, so that indexes no longer have to be in sync\n",
    "    2. Reduce the size of the numpy arrays as these will now not need spare slots at the end for merged jets\n",
    "        - could even experiment with repacking to ensure always dense packing of the numpy arrays\n",
    "\n",
    "This turned out to have far less impact that I was expecting - 10-15% reduction in runtime only\n",
    "- `numba2` results\n",
    "\n",
    "Profiling picked up that the `deepcopy` of the initial particles was having a very large impact (like 30% of runtime!). I adapted the code to avoid doing this in the timed loop\n",
    "- `numba3` results\n",
    "\n",
    "Realised that the `BasicJetInfo` class was not not needed - all of this state is tracked via the numpy arrays now. Removed that and got another speed up (~15%)\n",
    "- `numba4` results\n",
    "\n",
    "Aside - at this point I also commented out the `@njit` statements, just to understand what difference that would make. Looks like `numba` jitting is gaining around 40-50%.\n",
    "\n",
    "Commenting out `add_step_to_history` code gives another speed-up of about 15%, so actually the Python code that's left is now a significant drag on overall performance! But need to reimplement something else to get around that, as this actually stores the results.\n",
    "- Done (branch `history-numba`)\n",
    "- In fact speed up is very small ~2%!\n",
    "\n",
    "Discovered that removing all setter/getter code from `PseudoJet` is a but faster, so did that too\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerated Tiled Algorithm\n",
    "\n",
    "Need to have a think about to do this, but probably it needs to be a numpy array per-tile. This will require quite a lot more book-keeping, both to store the correct tiled structures and to keep track of the global state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Philippe's Implementation\n",
    "\n",
    "Track down the bug that is causing differences with FastJet for a few of the sample events\n",
    "- event 32\n",
    "- event 53"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, seeing minor differences in the numerical values of the antikt distance metric, e.g., for event 32:\n",
    "\n",
    "```\n",
    "py: Iteration 13: 0.0015722253198696117 for jet 122 and jet 181\n",
    "jl: Iteration 13: 0.0015722253198696043 for jet 122 and jet 181\n",
    "```\n",
    "\n",
    "Then get a major difference here:\n",
    "\n",
    "```\n",
    "py: Iteration 88: 0.0131507280901848 for jet 322 and jet 323\n",
    "jl: Iteration 88: 0.012617123337897836 for jet 683 and jet -1\n",
    "```\n",
    "\n",
    "This makes me suspect there is a bug in the Julia metric calculation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atell's Implementation\n",
    "\n",
    "Get this working with our HepMC input file, so that we have performance numbers for a basic Julia version\n",
    "\n",
    "Use branch `graeme-chep` running a new `main()` from `chep.jl`\n",
    "\n",
    "- Reads events from HepMC3\n",
    "    - Using Philippe's hepmc3jl wrapper package\n",
    "        - N.B. to get this to work you have to start the Julia package manager and do `(JetReconstruction) pkg> develop ./hepmc3jl`\n",
    "- Events are read into PseudoJet objects, then converted to the Vector{Vector{Float64}} used by Atell's code\n",
    "- Final results are recorded as FinalJet objects (rap, phi, pt)\n",
    "- Added timing code that can wrap multiple runs and time the code properly\n",
    "- Added dump option to dump final jets as JSON\n",
    "    - This was used to check the results: Atell's code agrees with FastJet and all Python implenentations, confirming there is a small bug in Philippe's code somewhere\n",
    "\n",
    "Results:\n",
    "\n",
    "`julia --project=. ./chep.jl --maxevents=100 --nsamples=100 --gcoff ./test/data/events.hepmc3`\n",
    "\n",
    "- Windows: Time per event 840.6328400000003 ± 101.1319694550256 μs\n",
    "- WSL Ubuntu: Time per event 949.3078376000002 ± 166.92048348307372 μs\n",
    "\n",
    "N.B. This is the only code that actually runs faster on Windows; the jitter on WSL is higher that makes the GC still suspect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antikt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
